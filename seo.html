<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>what is chatGPT?</title>
</head>
<body>
    <h1><center>what is chatGPT?</center></h1><img src="img/chatgpt3.png" alt="" >
    <h3><big> Article</big></h3>
    <!-- <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/ChatGPT.png/220px-ChatGPT.png" alt="" width="300px" style="display: block;margin: auto;"> -->
    <hr>
    <!-- 
    <header>
        <nav>
            <ul>
                <li>Home</li>
                <li>About</li>
                <li>Contact Us</li>
            </ul>
        </nav>
    </header>
     -->
    <main>
        <section>
            <div>
                <p>ChatGPT (Chat Generative Pre-trained Transformer) is a chatbot launched by OpenAI in November 2022.</p>
                <p>It is built on top of OpenAI's GPT-3 family of large language models, and is fine-tuned (an approach to transfer learning) with both supervised and reinforcement learning techniques.ChatGPT was launched as a prototype on November 30, 2022, and quickly garnered attention for its detailed responses and articulate answers across many domains of knowledge. Its uneven factual accuracy was identified as a significant drawback.Following the release of ChatGPT, OpenAI was valued at $29 billion.</p>
                
                <h3><big>Prepare</big></h3>
                <hr>
                <p>ChatGPT was fine-tuned on top of GPT-3.5 using supervised learning as well as reinforcement learning.Both approaches used human trainers to improve the model's performance. In the case of supervised learning, the model was provided with conversations in which the trainers played both sides: the user and the AI assistant. In the reinforcement step, human trainers first ranked responses that the model had created in a previous conversation. These rankings were used to create 'reward models' that the model was further fine-tuned on using several iterations of Proximal Policy Optimization (PPO).Proximal Policy Optimization algorithms present a cost-effective benefit to trust region policy optimization algorithms; they negate many of the computationally expensive operations with faster performance.The models were trained in collaboration with Microsoft on their Azure supercomputing infrastructure.</p>
                <h3>Features and limitations</h3>
                <hr>
                <p>Although the core function of a chatbot is to mimic a human conversationalist, ChatGPT is versatile. For example, it has the ability to write and debug computer programs; to compose music, teleplays, fairy tales, and student essays; to answer test questions (sometimes, depending on the test, at a level above the average human test-taker);to write poetry and song lyrics;to emulate a Linux system; to simulate an entire chat room; to play games like tic-tac-toe; and to simulate an ATM.ChatGPT's training data includes man pages and information about Internet phenomena and programming languages, such as bulletin board systems and the Python programming language.</p>
                <p></p>
                <img src="img/chatgpt2.png" alt="">
                <p>ChatGPT suffers from multiple limitations. OpenAI acknowledged that ChatGPT "sometimes writes plausible-sounding but incorrect or nonsensical answers". This behavior is common to large language models and is called hallucination. The reward model of ChatGPT, designed around human oversight, can be over-optimized and thus hinder performance, otherwise known as Goodhart's law.ChatGPT has limited knowledge of events that occurred after 2021. According to the BBC, as of December 2022 ChatGPT is not allowed to "express political opinions or engage in political activism". Yet, research suggests that ChatGPT exhibits a pro-environmental, left-libertarian orientation when prompted to take a stance on political statements from two established voting advice applications. In training ChatGPT, human reviewers preferred longer answers, irrespective of actual comprehension or factual content.Training data also suffers from algorithmic bias, which may be revealed when ChatGPT responds to prompts including descriptors of people. In one instance, ChatGPT generated a rap indicating that women and scientists of color were inferior to white and male scientists.</p>
            </div>
        </section>
    </main>
    <footer>
        <h3><center>Feedback</center></h3>
        <textarea name="feedback" id="feedback" cols="185" rows="4"></textarea>

        
        
    </footer>
    
</body>  
</html>